{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Midterm_UpdatedPreprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8PWGGuNsmFB",
        "colab_type": "code",
        "outputId": "d3fff17e-3b29-4945-8a57-ac7c55bb53b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from html.parser import HTMLParser\n",
        "import string\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk, pos_tag_sents\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import re\n",
        "from nltk.util import ngrams\n",
        "\n",
        "from nltk import RegexpParser\n",
        "from nltk import Tree\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwordList = stopwords.words('english')\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tarHrVrnsmFI",
        "colab_type": "code",
        "outputId": "f77df056-49f1-4d8a-a3ae-be1ec04435bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('pnlp_data_en.csv', delimiter=';')\n",
        "df.dropna()\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.max_rows', 50)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "\n",
        "# rename columns for easier usability\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "del df['report_grouping']\n",
        "del df['question_text']\n",
        "# preview\n",
        "df.head(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we do what our customers need, we communicate ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Customs business development continues to grow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think the team work hard, are committed to c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Overall working towards a customer centric env...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Customer centricity is a growing culture in th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments\n",
              "0  we do what our customers need, we communicate ...\n",
              "1  Customs business development continues to grow...\n",
              "2  I think the team work hard, are committed to c...\n",
              "3  Overall working towards a customer centric env...\n",
              "4  Customer centricity is a growing culture in th..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqhJPLYfwqei",
        "colab_type": "text"
      },
      "source": [
        "# Basic feature extraction from Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73Xx-gO4wn-Q",
        "colab_type": "code",
        "outputId": "c5150f1a-47c0-404b-b96c-b535f0823ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Total number of words per row\n",
        "feature_df = df.copy()\n",
        "feature_df['total_words'] = feature_df['comments'].apply(lambda x: len(str(x).split(\" \")))\n",
        "feature_df[['comments','total_words']].head(5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>total_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we do what our customers need, we communicate ...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Customs business development continues to grow...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think the team work hard, are committed to c...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Overall working towards a customer centric env...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Customer centricity is a growing culture in th...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  total_words\n",
              "0  we do what our customers need, we communicate ...            9\n",
              "1  Customs business development continues to grow...           28\n",
              "2  I think the team work hard, are committed to c...           19\n",
              "3  Overall working towards a customer centric env...           17\n",
              "4  Customer centricity is a growing culture in th...           15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVSjymfcx8u3",
        "colab_type": "code",
        "outputId": "97550cac-528a-4680-fbf9-ad8cdfb52c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Total number of characters (including space) per row\n",
        "feature_df['total_char'] = feature_df['comments'].str.len()\n",
        "feature_df[['comments','total_char']].head(5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>total_char</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we do what our customers need, we communicate ...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Customs business development continues to grow...</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think the team work hard, are committed to c...</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Overall working towards a customer centric env...</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Customer centricity is a growing culture in th...</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  total_char\n",
              "0  we do what our customers need, we communicate ...          60\n",
              "1  Customs business development continues to grow...         161\n",
              "2  I think the team work hard, are committed to c...         107\n",
              "3  Overall working towards a customer centric env...         117\n",
              "4  Customer centricity is a growing culture in th...         100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Z2yZRwyYNz",
        "colab_type": "code",
        "outputId": "e59d4b1b-6c5b-45f3-ad5f-3d2f0d6d135d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Total number of stopwords per row\n",
        "feature_df['stopwords'] = feature_df['comments'].apply(lambda x: len([x for x in x.split() if x in stopwordList]))\n",
        "feature_df[['comments','stopwords']].head(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we do what our customers need, we communicate ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Customs business development continues to grow...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think the team work hard, are committed to c...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Overall working towards a customer centric env...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Customer centricity is a growing culture in th...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  stopwords\n",
              "0  we do what our customers need, we communicate ...          5\n",
              "1  Customs business development continues to grow...         13\n",
              "2  I think the team work hard, are committed to c...          8\n",
              "3  Overall working towards a customer centric env...          5\n",
              "4  Customer centricity is a growing culture in th...          6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DUgp7gWzdx2",
        "colab_type": "code",
        "outputId": "34a63210-449d-447f-a2c6-d77eb3787104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Total number of punctuation or special characters per row\n",
        "feature_df['total_punc'] = feature_df['comments'].apply(lambda x: len([x for x in x.split() if x in string.punctuation]))\n",
        "feature_df[['comments','total_punc']].head(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>total_punc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we do what our customers need, we communicate ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Customs business development continues to grow...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think the team work hard, are committed to c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Overall working towards a customer centric env...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Customer centricity is a growing culture in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  total_punc\n",
              "0  we do what our customers need, we communicate ...           0\n",
              "1  Customs business development continues to grow...           1\n",
              "2  I think the team work hard, are committed to c...           0\n",
              "3  Overall working towards a customer centric env...           0\n",
              "4  Customer centricity is a growing culture in th...           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwKPFE2C2z_X",
        "colab_type": "code",
        "outputId": "629fcb08-0c8d-4d72-d8c7-8d098f6ad4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Total number of numerics per row\n",
        "feature_df['total_num'] = feature_df['comments'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
        "feature_df[['comments','total_num']].head(5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>total_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we do what our customers need, we communicate ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Customs business development continues to grow...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think the team work hard, are committed to c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Overall working towards a customer centric env...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Customer centricity is a growing culture in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  total_num\n",
              "0  we do what our customers need, we communicate ...          0\n",
              "1  Customs business development continues to grow...          0\n",
              "2  I think the team work hard, are committed to c...          0\n",
              "3  Overall working towards a customer centric env...          0\n",
              "4  Customer centricity is a growing culture in th...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHl8YObZ3aY6",
        "colab_type": "code",
        "outputId": "2d5b31b8-5db9-47b9-8579-3629f58f3ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Total number of Uppercase word per row\n",
        "feature_df['total_uppercase'] = feature_df['comments'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
        "feature_df[['comments','total_uppercase']].head(5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>total_uppercase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we do what our customers need, we communicate ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Customs business development continues to grow...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think the team work hard, are committed to c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Overall working towards a customer centric env...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Customer centricity is a growing culture in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  total_uppercase\n",
              "0  we do what our customers need, we communicate ...                0\n",
              "1  Customs business development continues to grow...                0\n",
              "2  I think the team work hard, are committed to c...                1\n",
              "3  Overall working towards a customer centric env...                0\n",
              "4  Customer centricity is a growing culture in th...                0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYTZSrErsmFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apostrophe Dictionary and if you have more words in mind, please add it in the bottom\n",
        "apostrophe = {\n",
        "    \"aren't\" : \"are not\",\n",
        "    \"can't\" : \"cannot\",\n",
        "    \"couldn't\" : \"could not\",\n",
        "    \"didn't\" : \"did not\",\n",
        "    \"doesn't\" : \"does not\",\n",
        "    \"don't\" : \"do not\",\n",
        "    \"hadn't\" : \"had not\",\n",
        "    \"hasn't\" : \"has not\",\n",
        "    \"haven't\" : \"have not\",\n",
        "    \"he'd\" : \"he would\",\n",
        "    \"he'll\" : \"he will\",\n",
        "    \"he's\" : \"he is\",\n",
        "    \"i'd\" : \"I would\",\n",
        "    \"i'd\" : \"I had\",\n",
        "    \"i'll\" : \"I will\",\n",
        "    \"i'm\" : \"I am\",\n",
        "    \"isn't\" : \"is not\",\n",
        "    \"it's\" : \"it is\",\n",
        "    \"it'll\":\"it will\",\n",
        "    \"i've\" : \"I have\",\n",
        "    \"let's\" : \"let us\",\n",
        "    \"mightn't\" : \"might not\",\n",
        "    \"mustn't\" : \"must not\",\n",
        "    \"shan't\" : \"shall not\",\n",
        "    \"she'd\" : \"she would\",\n",
        "    \"she'll\" : \"she will\",\n",
        "    \"she's\" : \"she is\",\n",
        "    \"shouldn't\" : \"should not\",\n",
        "    \"that's\" : \"that is\",\n",
        "    \"there's\" : \"there is\",\n",
        "    \"they'd\" : \"they would\",\n",
        "    \"they'll\" : \"they will\",\n",
        "    \"they're\" : \"they are\",\n",
        "    \"they've\" : \"they have\",\n",
        "    \"we'd\" : \"we would\",\n",
        "    \"we're\" : \"we are\",\n",
        "    \"weren't\" : \"were not\",\n",
        "    \"we've\" : \"we have\",\n",
        "    \"what'll\" : \"what will\",\n",
        "    \"what're\" : \"what are\",\n",
        "    \"what's\" : \"what is\",\n",
        "    \"what've\" : \"what have\",\n",
        "    \"where's\" : \"where is\",\n",
        "    \"who'd\" : \"who would\",\n",
        "    \"who'll\" : \"who will\",\n",
        "    \"who're\" : \"who are\",\n",
        "    \"who's\" : \"who is\",\n",
        "    \"who've\" : \"who have\",\n",
        "    \"won't\" : \"will not\",\n",
        "    \"wouldn't\" : \"would not\",\n",
        "    \"you'd\" : \"you would\",\n",
        "    \"you'll\" : \"you will\",\n",
        "    \"you're\" : \"you are\",\n",
        "    \"you've\" : \"you have\",\n",
        "    \"'re\": \" are\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'll\":\" will\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"'s\": \"is\",\n",
        "    \"'re\": \"are\"\n",
        "}\n",
        "\n",
        "#Short words dictionary and if have more words in mind, please add it in the bottom\n",
        "short_words = {\n",
        "\"121\": \"one to one\",\n",
        "\"a/s/l\": \"age, sex, location\",\n",
        "\"adn\": \"any day now\",\n",
        "\"afaik\": \"as far as I know\",\n",
        "\"afk\": \"away from keyboard\",\n",
        "\"aight\": \"alright\",\n",
        "\"alol\": \"actually laughing out loud\",\n",
        "\"b4\": \"before\",\n",
        "\"b4n\": \"bye for now\",\n",
        "\"bak\": \"back at the keyboard\",\n",
        "\"bf\": \"boyfriend\",\n",
        "\"bff\": \"best friends forever\",\n",
        "\"bfn\": \"bye for now\",\n",
        "\"bg\": \"big grin\",\n",
        "\"bta\": \"but then again\",\n",
        "\"btw\": \"by the way\",\n",
        "\"cid\": \"crying in disgrace\",\n",
        "\"cnp\": \"continued in my next post\",\n",
        "\"cp\": \"chat post\",\n",
        "\"cu\": \"see you\",\n",
        "\"cul\": \"see you later\",\n",
        "\"cul8r\": \"see you later\",\n",
        "\"cya\": \"bye\",\n",
        "\"cyo\": \"see you online\",\n",
        "\"dbau\": \"doing business as usual\",\n",
        "\"fud\": \"fear, uncertainty, and doubt\",\n",
        "\"fwiw\": \"for what it's worth\",\n",
        "\"fyi\": \"for your information\",\n",
        "\"g\": \"grin\",\n",
        "\"g2g\": \"got to go\",\n",
        "\"ga\": \"go ahead\",\n",
        "\"gal\": \"get a life\",\n",
        "\"gf\": \"girlfriend\",\n",
        "\"gfn\": \"gone for now\",\n",
        "\"gmbo\": \"giggling my butt off\",\n",
        "\"gmta\": \"great minds think alike\",\n",
        "\"h8\": \"hate\",\n",
        "\"hagn\": \"have a good night\",\n",
        "\"hdop\": \"help delete online predators\",\n",
        "\"hhis\": \"hanging head in shame\",\n",
        "\"iac\": \"in any case\",\n",
        "\"ianal\": \"I am not a lawyer\",\n",
        "\"ic\": \"I see\",\n",
        "\"idk\": \"I don't know\",\n",
        "\"imao\": \"in my arrogant opinion\",\n",
        "\"imnsho\": \"in my not so humble opinion\",\n",
        "\"imo\": \"in my opinion\",\n",
        "\"iow\": \"in other words\",\n",
        "\"ipn\": \"I’m posting naked\",\n",
        "\"irl\": \"in real life\",\n",
        "\"jk\": \"just kidding\",\n",
        "\"l8r\": \"later\",\n",
        "\"ld\": \"later, dude\",\n",
        "\"ldr\": \"long distance relationship\",\n",
        "\"llta\": \"lots and lots of thunderous applause\",\n",
        "\"lmao\": \"laugh my ass off\",\n",
        "\"lmirl\": \"let's meet in real life\",\n",
        "\"lol\": \"laugh out loud\",\n",
        "\"ltr\": \"longterm relationship\",\n",
        "\"lulab\": \"love you like a brother\",\n",
        "\"lulas\": \"love you like a sister\",\n",
        "\"luv\": \"love\",\n",
        "\"m/f\": \"male or female\",\n",
        "\"m8\": \"mate\",\n",
        "\"milf\": \"mother I would like to fuck\",\n",
        "\"oll\": \"online love\",\n",
        "\"omg\": \"oh my god\",\n",
        "\"otoh\": \"on the other hand\",\n",
        "\"pir\": \"parent in room\",\n",
        "\"ppl\": \"people\",\n",
        "\"r\": \"are\",\n",
        "\"rofl\": \"roll on the floor laughing\",\n",
        "\"rpg\": \"role playing games\",\n",
        "\"ru\": \"are you\",\n",
        "\"shid\": \"slaps head in disgust\",\n",
        "\"somy\": \"sick of me yet\",\n",
        "\"sot\": \"short of time\",\n",
        "\"thanx\": \"thanks\",\n",
        "\"thx\": \"thanks\",\n",
        "\"ttyl\": \"talk to you later\",\n",
        "\"u\": \"you\",\n",
        "\"ur\": \"you are\",\n",
        "\"uw\": \"you’re welcome\",\n",
        "\"wb\": \"welcome back\",\n",
        "\"wfm\": \"works for me\",\n",
        "\"wibni\": \"wouldn't it be nice if\",\n",
        "\"wtf\": \"what the fuck\",\n",
        "\"wtg\": \"way to go\",\n",
        "\"wtgp\": \"want to go private\",\n",
        "\"ym\": \"young man\",\n",
        "\"gr8\": \"great\"\n",
        "}\n",
        "\n",
        "def apos_short_dict(text, dictionary):\n",
        "    for word in text.split():\n",
        "        if word.lower() in dictionary:\n",
        "            if word.lower() in text.split():\n",
        "                text = text.replace(word, dictionary[word.lower()])\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5lQP5RY73__",
        "colab_type": "text"
      },
      "source": [
        "# **Basic Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XSox5oAsmFP",
        "colab_type": "code",
        "outputId": "93acbfca-8c3e-4f47-af7c-2b0d6174e51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def remove_html(txt):\n",
        "    '''Remove HTML'''\n",
        "    txt = BeautifulSoup(txt, 'lxml')\n",
        "    return txt.get_text()\n",
        "\n",
        "def remove_punctuation(surveyText):\n",
        "    '''Remove any punctuation'''\n",
        "    return \"\".join([i for i in surveyText if i not in string.punctuation])\n",
        "\n",
        "def remove_stopwords(surveyText):\n",
        "    '''Remove stop words'''\n",
        "    return [w for w in surveyText if w not in stopwordList]\n",
        "\n",
        "def word_lemmatizer(surveyText):\n",
        "    '''Lemmatize words'''\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    w_tokenizer = WhitespaceTokenizer()\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(surveyText)]\n",
        "\n",
        "def word_stemmer(surveyText):\n",
        "    '''Stem word'''\n",
        "    stemmer = PorterStemmer()\n",
        "    return [stemmer.stem(i) for i in surveyText]\n",
        "\n",
        "# Function to generate n-grams from sentences.\n",
        "def extract_ngrams(txt, num=3):\n",
        "    n_grams = ngrams(nltk.word_tokenize(txt), num)\n",
        "    return [ ' '.join(grams) for grams in n_grams]\n",
        "    \n",
        "'''\n",
        "def pos_tags(txt):\n",
        "  \n",
        "  tokenized = sent_tokenize(txt) \n",
        "  for i in tokenized: \n",
        "      \n",
        "    # Word tokenizers is used to find the words  \n",
        "    # and punctuation in a string \n",
        "    wordsList = nltk.word_tokenize(i) \n",
        "  \n",
        "    # removing stop words from wordList \n",
        "    wordsList = [w for w in wordsList if not w in stop_words]  \n",
        "  \n",
        "    #  Using a Tagger. Which is part-of-speech  \n",
        "    # tagger or POS-tagger.  \n",
        "    tagged = nltk.pos_tag(wordsList) \n",
        "    return [ ' '.join(tags) for tags in tagged]\n",
        "    #print(tagged)\n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "    Control the parameter by putting value of TRUE or FALSE according to requirements. \n",
        "    Args : txt - Provided text for preprocessing\n",
        "            punctuation - Remove all punctuation, Initially value = False\n",
        "            tokenize - Splitting long text into smaller lines\n",
        "            stopwords - Remove such words which does not have much meaning to a line of text\n",
        "            correct_apos - Remove apostrophe\n",
        "            shortwords - Convert any short word to full meaningfull word\n",
        "            specialCharacter - Replace all specialCharacter\n",
        "            numbers - Remove numbers\n",
        "            singleChar - Removing words whom length is one\n",
        "            lematization - Lematize text\n",
        "            stemming - Stemming any text\n",
        "'''\n",
        "def preprocessing(txt, punctuation= False, tokenize= False, stopwords= False, correct_apos= False, \n",
        "                  shortWords= False, specialCharacter= False, numbers= False, singleChar= False,\n",
        "                 lematization= False, stemming= False, ngrams=False):\n",
        "    \n",
        "    cleanedTxt = txt.apply(lambda x: remove_html(x))\n",
        "    \n",
        "    if punctuation:\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x:remove_punctuation(x))\n",
        "    \n",
        "    #if spellCheck:\n",
        "        #cleanedTxt = cleanedTxt.apply(lambda x: spell_correction(x))\n",
        "        \n",
        "    if tokenize:\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x:word_tokenize(x.lower()))\n",
        "        \n",
        "    if stopwords:\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x: remove_stopwords(x))\n",
        "        \n",
        "    if correct_apos:\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x: apos_short_dict(str(x),apostrophe))\n",
        "        \n",
        "    if shortWords:\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x: apos_short_dict(str(x),short_words))\n",
        "    \n",
        "    if specialCharacter:\n",
        "        '''Replacing Special Characters with space'''\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',str(x)))\n",
        "    \n",
        "    if numbers:\n",
        "        '''Replacing Numbers with space'''\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x: re.sub(r'[^a-zA-Z]',' ',x))\n",
        "        \n",
        "    if singleChar:\n",
        "        '''Removing words whom length is one'''\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))\n",
        "    \n",
        "    if lematization:\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x: word_lemmatizer(x))\n",
        "        \n",
        "    if stemming:\n",
        "        cleanedTxt = cleanedTxt.apply(lambda x: word_stemmer(x))\n",
        "\n",
        "    #if ngrams:\n",
        "        #cleanedTxt = cleanedTxt.apply(lambda x: extract_ngrams(x))\n",
        "    \n",
        "    return cleanedTxt\n",
        "      \n",
        "df['comments'] = preprocessing(df['comments'], punctuation= True, tokenize= True, stopwords= True, \n",
        "                                correct_apos= True, shortWords= True, specialCharacter= True, \n",
        "                               numbers= True, singleChar= True, lematization= False, stemming= False, ngrams= True)\n",
        "df.head(5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>customers need communicate aperiodically</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>customs business development continues grow ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>think team work hard committed continuous impr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>overall working towards customer centric envir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>customer centricity growing culture company cr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments\n",
              "0           customers need communicate aperiodically\n",
              "1  customs business development continues grow ex...\n",
              "2  think team work hard committed continuous impr...\n",
              "3  overall working towards customer centric envir...\n",
              "4  customer centricity growing culture company cr..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeSRXdDP7pOG",
        "colab_type": "code",
        "outputId": "cd6ce8c9-0697-4cd4-e5ec-5e51be8172f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Sentence tokenization\n",
        "df['tokenized_sents'] = df['comments'].apply(lambda x: nltk.sent_tokenize(x))\n",
        "df.head(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>tokenized_sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>customers need communicate aperiodically</td>\n",
              "      <td>[customers need communicate aperiodically]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>customs business development continues grow ex...</td>\n",
              "      <td>[customs business development continues grow e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>think team work hard committed continuous impr...</td>\n",
              "      <td>[think team work hard committed continuous imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>overall working towards customer centric envir...</td>\n",
              "      <td>[overall working towards customer centric envi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>customer centricity growing culture company cr...</td>\n",
              "      <td>[customer centricity growing culture company c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  \\\n",
              "0           customers need communicate aperiodically   \n",
              "1  customs business development continues grow ex...   \n",
              "2  think team work hard committed continuous impr...   \n",
              "3  overall working towards customer centric envir...   \n",
              "4  customer centricity growing culture company cr...   \n",
              "\n",
              "                                     tokenized_sents  \n",
              "0         [customers need communicate aperiodically]  \n",
              "1  [customs business development continues grow e...  \n",
              "2  [think team work hard committed continuous imp...  \n",
              "3  [overall working towards customer centric envi...  \n",
              "4  [customer centricity growing culture company c...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JboqeEto7pgW",
        "colab_type": "code",
        "outputId": "1cd5d73b-a0e5-4664-aeb0-a72c3526a3b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Word Tokenization\n",
        "df['tokenized_words'] = df['comments'].apply(lambda x: nltk.word_tokenize(x))\n",
        "df.head(5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>tokenized_sents</th>\n",
              "      <th>tokenized_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>customers need communicate aperiodically</td>\n",
              "      <td>[customers need communicate aperiodically]</td>\n",
              "      <td>[customers, need, communicate, aperiodically]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>customs business development continues grow ex...</td>\n",
              "      <td>[customs business development continues grow e...</td>\n",
              "      <td>[customs, business, development, continues, gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>think team work hard committed continuous impr...</td>\n",
              "      <td>[think team work hard committed continuous imp...</td>\n",
              "      <td>[think, team, work, hard, committed, continuou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>overall working towards customer centric envir...</td>\n",
              "      <td>[overall working towards customer centric envi...</td>\n",
              "      <td>[overall, working, towards, customer, centric,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>customer centricity growing culture company cr...</td>\n",
              "      <td>[customer centricity growing culture company c...</td>\n",
              "      <td>[customer, centricity, growing, culture, compa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  \\\n",
              "0           customers need communicate aperiodically   \n",
              "1  customs business development continues grow ex...   \n",
              "2  think team work hard committed continuous impr...   \n",
              "3  overall working towards customer centric envir...   \n",
              "4  customer centricity growing culture company cr...   \n",
              "\n",
              "                                     tokenized_sents  \\\n",
              "0         [customers need communicate aperiodically]   \n",
              "1  [customs business development continues grow e...   \n",
              "2  [think team work hard committed continuous imp...   \n",
              "3  [overall working towards customer centric envi...   \n",
              "4  [customer centricity growing culture company c...   \n",
              "\n",
              "                                     tokenized_words  \n",
              "0      [customers, need, communicate, aperiodically]  \n",
              "1  [customs, business, development, continues, gr...  \n",
              "2  [think, team, work, hard, committed, continuou...  \n",
              "3  [overall, working, towards, customer, centric,...  \n",
              "4  [customer, centricity, growing, culture, compa...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puQszxS9-HFw",
        "colab_type": "code",
        "outputId": "8c536792-7f8d-4649-c793-6b6c1af20c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# POS tagging\n",
        "df['POS_Tags'] = pos_tag_sents(df['comments'].apply(word_tokenize).tolist())\n",
        "df.head(5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>tokenized_sents</th>\n",
              "      <th>tokenized_words</th>\n",
              "      <th>POS_Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>customers need communicate aperiodically</td>\n",
              "      <td>[customers need communicate aperiodically]</td>\n",
              "      <td>[customers, need, communicate, aperiodically]</td>\n",
              "      <td>[(customers, NNS), (need, VBP), (communicate, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>customs business development continues grow ex...</td>\n",
              "      <td>[customs business development continues grow e...</td>\n",
              "      <td>[customs, business, development, continues, gr...</td>\n",
              "      <td>[(customs, NNS), (business, NN), (development,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>think team work hard committed continuous impr...</td>\n",
              "      <td>[think team work hard committed continuous imp...</td>\n",
              "      <td>[think, team, work, hard, committed, continuou...</td>\n",
              "      <td>[(think, NN), (team, NN), (work, NN), (hard, R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>overall working towards customer centric envir...</td>\n",
              "      <td>[overall working towards customer centric envi...</td>\n",
              "      <td>[overall, working, towards, customer, centric,...</td>\n",
              "      <td>[(overall, JJ), (working, NN), (towards, NNS),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>customer centricity growing culture company cr...</td>\n",
              "      <td>[customer centricity growing culture company c...</td>\n",
              "      <td>[customer, centricity, growing, culture, compa...</td>\n",
              "      <td>[(customer, NN), (centricity, NN), (growing, V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  \\\n",
              "0           customers need communicate aperiodically   \n",
              "1  customs business development continues grow ex...   \n",
              "2  think team work hard committed continuous impr...   \n",
              "3  overall working towards customer centric envir...   \n",
              "4  customer centricity growing culture company cr...   \n",
              "\n",
              "                                     tokenized_sents  \\\n",
              "0         [customers need communicate aperiodically]   \n",
              "1  [customs business development continues grow e...   \n",
              "2  [think team work hard committed continuous imp...   \n",
              "3  [overall working towards customer centric envi...   \n",
              "4  [customer centricity growing culture company c...   \n",
              "\n",
              "                                     tokenized_words  \\\n",
              "0      [customers, need, communicate, aperiodically]   \n",
              "1  [customs, business, development, continues, gr...   \n",
              "2  [think, team, work, hard, committed, continuou...   \n",
              "3  [overall, working, towards, customer, centric,...   \n",
              "4  [customer, centricity, growing, culture, compa...   \n",
              "\n",
              "                                            POS_Tags  \n",
              "0  [(customers, NNS), (need, VBP), (communicate, ...  \n",
              "1  [(customs, NNS), (business, NN), (development,...  \n",
              "2  [(think, NN), (team, NN), (work, NN), (hard, R...  \n",
              "3  [(overall, JJ), (working, NN), (towards, NNS),...  \n",
              "4  [(customer, NN), (centricity, NN), (growing, V...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeDHNI58E4W_",
        "colab_type": "code",
        "outputId": "a8186f68-bba7-4342-c92d-b8081c751230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Term frequency\n",
        "# TF = (Number of times term T appears in the particular row) / (number of terms in that row)\n",
        "df1 = (df['comments']).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
        "df1.columns = ['words','tf']\n",
        "df1.head(5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>tf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>customers</td>\n",
              "      <td>918.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>communicate</td>\n",
              "      <td>116.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aperiodically</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>need</td>\n",
              "      <td>2373.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>business</td>\n",
              "      <td>650.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           words      tf\n",
              "0      customers   918.0\n",
              "1    communicate   116.0\n",
              "2  aperiodically     1.0\n",
              "3           need  2373.0\n",
              "4       business   650.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT7K6JsvF809",
        "colab_type": "code",
        "outputId": "95a57df9-a543-404a-fde9-6097b13d4612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Inverse Document Frequency\n",
        "# IDF = log(N/n), where, N is the total number of rows and n is the number of rows in which the word was present\n",
        "for i,word in enumerate(df1['words']):\n",
        "  df1.loc[i, 'idf'] = np.log(df1.shape[0]/(len(df1[df1['words'].str.contains(word)])))\n",
        "\n",
        "df1.head(5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>tf</th>\n",
              "      <th>idf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>customers</td>\n",
              "      <td>918.0</td>\n",
              "      <td>6.506905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>communicate</td>\n",
              "      <td>116.0</td>\n",
              "      <td>7.710877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aperiodically</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.502637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>need</td>\n",
              "      <td>2373.0</td>\n",
              "      <td>6.170432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>business</td>\n",
              "      <td>650.0</td>\n",
              "      <td>7.200052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           words      tf       idf\n",
              "0      customers   918.0  6.506905\n",
              "1    communicate   116.0  7.710877\n",
              "2  aperiodically     1.0  9.502637\n",
              "3           need  2373.0  6.170432\n",
              "4       business   650.0  7.200052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AaOLQQhIUQR",
        "colab_type": "code",
        "outputId": "3ab044b8-b27e-4193-bd89-9fe0d5f9819e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Term Frequency – Inverse Document Frequency (TF-IDF)\n",
        "# TF-IDF = TF * IDF\n",
        "\n",
        "df1['tf_idf'] = df1['tf'] * df1['idf']\n",
        "df1.head(5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>tf</th>\n",
              "      <th>idf</th>\n",
              "      <th>tf_idf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>customers</td>\n",
              "      <td>918.0</td>\n",
              "      <td>6.506905</td>\n",
              "      <td>5973.338339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>communicate</td>\n",
              "      <td>116.0</td>\n",
              "      <td>7.710877</td>\n",
              "      <td>894.461768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aperiodically</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.502637</td>\n",
              "      <td>9.502637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>need</td>\n",
              "      <td>2373.0</td>\n",
              "      <td>6.170432</td>\n",
              "      <td>14642.435781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>business</td>\n",
              "      <td>650.0</td>\n",
              "      <td>7.200052</td>\n",
              "      <td>4680.033598</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           words      tf       idf        tf_idf\n",
              "0      customers   918.0  6.506905   5973.338339\n",
              "1    communicate   116.0  7.710877    894.461768\n",
              "2  aperiodically     1.0  9.502637      9.502637\n",
              "3           need  2373.0  6.170432  14642.435781\n",
              "4       business   650.0  7.200052   4680.033598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW8LKJ0tJEFd",
        "colab_type": "code",
        "outputId": "a080c089-6a1f-4d73-f477-3a340b187e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Chunking\n",
        "\n",
        "def get_continuous_chunks(text, chunk_func=ne_chunk):\n",
        "    #print(text)\n",
        "    #exit()\n",
        "    chunked = chunk_func(pos_tag(word_tokenize(text)))\n",
        "    continuous_chunk = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for subtree in chunked:\n",
        "        if type(subtree) == Tree:\n",
        "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
        "        elif current_chunk:\n",
        "            named_entity = \" \".join(current_chunk)\n",
        "            if named_entity not in continuous_chunk:\n",
        "                continuous_chunk.append(named_entity)\n",
        "                current_chunk = []\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    return continuous_chunk\n",
        "\n",
        "df['comments'].apply(lambda sent: get_continuous_chunks((sent)))\n",
        "df.head(5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>tokenized_sents</th>\n",
              "      <th>tokenized_words</th>\n",
              "      <th>POS_Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>customers need communicate aperiodically</td>\n",
              "      <td>[customers need communicate aperiodically]</td>\n",
              "      <td>[customers, need, communicate, aperiodically]</td>\n",
              "      <td>[(customers, NNS), (need, VBP), (communicate, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>customs business development continues grow ex...</td>\n",
              "      <td>[customs business development continues grow e...</td>\n",
              "      <td>[customs, business, development, continues, gr...</td>\n",
              "      <td>[(customs, NNS), (business, NN), (development,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>think team work hard committed continuous impr...</td>\n",
              "      <td>[think team work hard committed continuous imp...</td>\n",
              "      <td>[think, team, work, hard, committed, continuou...</td>\n",
              "      <td>[(think, NN), (team, NN), (work, NN), (hard, R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>overall working towards customer centric envir...</td>\n",
              "      <td>[overall working towards customer centric envi...</td>\n",
              "      <td>[overall, working, towards, customer, centric,...</td>\n",
              "      <td>[(overall, JJ), (working, NN), (towards, NNS),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>customer centricity growing culture company cr...</td>\n",
              "      <td>[customer centricity growing culture company c...</td>\n",
              "      <td>[customer, centricity, growing, culture, compa...</td>\n",
              "      <td>[(customer, NN), (centricity, NN), (growing, V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  \\\n",
              "0           customers need communicate aperiodically   \n",
              "1  customs business development continues grow ex...   \n",
              "2  think team work hard committed continuous impr...   \n",
              "3  overall working towards customer centric envir...   \n",
              "4  customer centricity growing culture company cr...   \n",
              "\n",
              "                                     tokenized_sents  \\\n",
              "0         [customers need communicate aperiodically]   \n",
              "1  [customs business development continues grow e...   \n",
              "2  [think team work hard committed continuous imp...   \n",
              "3  [overall working towards customer centric envi...   \n",
              "4  [customer centricity growing culture company c...   \n",
              "\n",
              "                                     tokenized_words  \\\n",
              "0      [customers, need, communicate, aperiodically]   \n",
              "1  [customs, business, development, continues, gr...   \n",
              "2  [think, team, work, hard, committed, continuou...   \n",
              "3  [overall, working, towards, customer, centric,...   \n",
              "4  [customer, centricity, growing, culture, compa...   \n",
              "\n",
              "                                            POS_Tags  \n",
              "0  [(customers, NNS), (need, VBP), (communicate, ...  \n",
              "1  [(customs, NNS), (business, NN), (development,...  \n",
              "2  [(think, NN), (team, NN), (work, NN), (hard, R...  \n",
              "3  [(overall, JJ), (working, NN), (towards, NNS),...  \n",
              "4  [(customer, NN), (centricity, NN), (growing, V...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAuxa51QPr6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNJIQQkqsmFT",
        "colab_type": "code",
        "outputId": "b3f66323-7ac7-4d09-ddee-cca708e81638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# de-tokenization\n",
        "detokenizer = []\n",
        "for i in range(len(df)):\n",
        "    t = ' '.join(df['comments'][i]) # tokenized text\n",
        "    detokenizer.append(t)\n",
        "\n",
        "df['comments'] = detokenizer\n",
        "df.head(5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>tokenized_sents</th>\n",
              "      <th>tokenized_words</th>\n",
              "      <th>POS_Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c u s t o m e r s   n e e d   c o m m u n i c ...</td>\n",
              "      <td>[customers need communicate aperiodically]</td>\n",
              "      <td>[customers, need, communicate, aperiodically]</td>\n",
              "      <td>[(customers, NNS), (need, VBP), (communicate, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c u s t o m s   b u s i n e s s   d e v e l o ...</td>\n",
              "      <td>[customs business development continues grow e...</td>\n",
              "      <td>[customs, business, development, continues, gr...</td>\n",
              "      <td>[(customs, NNS), (business, NN), (development,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>t h i n k   t e a m   w o r k   h a r d   c o ...</td>\n",
              "      <td>[think team work hard committed continuous imp...</td>\n",
              "      <td>[think, team, work, hard, committed, continuou...</td>\n",
              "      <td>[(think, NN), (team, NN), (work, NN), (hard, R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>o v e r a l l   w o r k i n g   t o w a r d s ...</td>\n",
              "      <td>[overall working towards customer centric envi...</td>\n",
              "      <td>[overall, working, towards, customer, centric,...</td>\n",
              "      <td>[(overall, JJ), (working, NN), (towards, NNS),...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c u s t o m e r   c e n t r i c i t y   g r o ...</td>\n",
              "      <td>[customer centricity growing culture company c...</td>\n",
              "      <td>[customer, centricity, growing, culture, compa...</td>\n",
              "      <td>[(customer, NN), (centricity, NN), (growing, V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            comments  \\\n",
              "0  c u s t o m e r s   n e e d   c o m m u n i c ...   \n",
              "1  c u s t o m s   b u s i n e s s   d e v e l o ...   \n",
              "2  t h i n k   t e a m   w o r k   h a r d   c o ...   \n",
              "3  o v e r a l l   w o r k i n g   t o w a r d s ...   \n",
              "4  c u s t o m e r   c e n t r i c i t y   g r o ...   \n",
              "\n",
              "                                     tokenized_sents  \\\n",
              "0         [customers need communicate aperiodically]   \n",
              "1  [customs business development continues grow e...   \n",
              "2  [think team work hard committed continuous imp...   \n",
              "3  [overall working towards customer centric envi...   \n",
              "4  [customer centricity growing culture company c...   \n",
              "\n",
              "                                     tokenized_words  \\\n",
              "0      [customers, need, communicate, aperiodically]   \n",
              "1  [customs, business, development, continues, gr...   \n",
              "2  [think, team, work, hard, committed, continuou...   \n",
              "3  [overall, working, towards, customer, centric,...   \n",
              "4  [customer, centricity, growing, culture, compa...   \n",
              "\n",
              "                                            POS_Tags  \n",
              "0  [(customers, NNS), (need, VBP), (communicate, ...  \n",
              "1  [(customs, NNS), (business, NN), (development,...  \n",
              "2  [(think, NN), (team, NN), (work, NN), (hard, R...  \n",
              "3  [(overall, JJ), (working, NN), (towards, NNS),...  \n",
              "4  [(customer, NN), (centricity, NN), (growing, V...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eib6U_NRZiG0",
        "colab_type": "code",
        "outputId": "c8ac1d13-0ea4-4a73-c1c4-cbc974d7e941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "# Coreference Resolution\n",
        "# Need to download and extract\n",
        "  # !wget http://nlp.stanford.edu/software/stanford-corenlp-latest.zip\n",
        "  # !unzip stanford-corenlp-latest.zip\n",
        "# After extraction goto the command promt and navigate to the extracted folder and run the below given command.\n",
        "# Then execute the program\n",
        "  # java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer\n",
        "\n",
        "# [Note] Port number is by default 9000 but it can be change.\n",
        "\n",
        "!pip install pycorenlp\n",
        "from pycorenlp import StanfordCoreNLP\n",
        "\n",
        "nlp = StanfordCoreNLP('http://localhost:9000')\n",
        "\n",
        "\n",
        "def resolve(corenlp_output):\n",
        "    \"\"\" Transfer the word form of the antecedent to its associated pronominal anaphor(s) \"\"\"\n",
        "    for coref in corenlp_output['corefs']:\n",
        "        mentions = corenlp_output['corefs'][coref]\n",
        "        antecedent = mentions[0]  # the antecedent is the first mention in the coreference chain\n",
        "        for j in range(1, len(mentions)):\n",
        "            mention = mentions[j]\n",
        "            if mention['type'] == 'PRONOMINAL':\n",
        "                # get the attributes of the target mention in the corresponding sentence\n",
        "                target_sentence = mention['sentNum']\n",
        "                target_token = mention['startIndex'] - 1\n",
        "                # transfer the antecedent's word form to the appropriate token in the sentence\n",
        "                corenlp_output['sentences'][target_sentence - 1]['tokens'][target_token]['word'] = antecedent['text']\n",
        "\n",
        "\n",
        "def print_resolved(corenlp_output):\n",
        "    \"\"\" Print the \"resolved\" output \"\"\"\n",
        "    possessives = ['hers', 'his', 'their', 'theirs']\n",
        "    for sentence in corenlp_output['sentences']:\n",
        "        for token in sentence['tokens']:\n",
        "            output_word = token['word']\n",
        "            # check lemmas as well as tags for possessive pronouns in case of tagging errors\n",
        "            if token['lemma'] in possessives or token['pos'] == 'PRP$':\n",
        "                output_word += \"'s\"  # add the possessive morpheme\n",
        "            output_word += token['after']\n",
        "            print(output_word, end='')\n",
        "\n",
        "for i in range(len(df)):\n",
        "    output = nlp.annotate(df['comments'].iloc[i], properties= {'annotators':'dcoref','outputFormat':'json','ner.useSUTime':'false'})\n",
        "    resolve(output)\n",
        "    \n",
        "    print('Original:', df['comment'].iloc[i] )\n",
        "    print('Resolved: ', end='')\n",
        "    print_resolved(output)\n",
        "    print('-'*50)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycorenlp\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/40/e74eb4fc7906d630b73a84c9ae9d824f694bd4c5a1d727b8e18beadff613/pycorenlp-0.3.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pycorenlp) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pycorenlp) (1.24.3)\n",
            "Building wheels for collected packages: pycorenlp\n",
            "  Building wheel for pycorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycorenlp: filename=pycorenlp-0.3.0-cp36-none-any.whl size=2143 sha256=d4cb043bf307fbe3c46364b5a6553f5dbac64650730c3e5a8382dfe585d55fc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/e9/2f/767a7b5f2e82d587a36143c04a21839b4b14bebfb89410d2d5\n",
            "Successfully built pycorenlp\n",
            "Installing collected packages: pycorenlp\n",
            "Successfully installed pycorenlp-0.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fdf3b2595f8>: Failed to establish a new connection: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdf3b2595f8>: Failed to establish a new connection: [Errno 111] Connection refused',))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycorenlp/corenlp.py\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(self, text, properties)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdf3b2595f8>: Failed to establish a new connection: [Errno 111] Connection refused',))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-bec2eb572b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'annotators'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'dcoref'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'outputFormat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ner.useSUTime'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'false'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pycorenlp/corenlp.py\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(self, text, properties)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             raise Exception('Check whether you have started the CoreNLP server e.g.\\n'\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;34m'$ cd stanford-corenlp-full-2015-12-09/ \\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             '$ java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer')\n",
            "\u001b[0;31mException\u001b[0m: Check whether you have started the CoreNLP server e.g.\n$ cd stanford-corenlp-full-2015-12-09/ \n$ java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2mUSmQTRGL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO ##\n",
        "# Ngrams\n",
        "# Extract Collocation\n",
        "# Named Entity Recognition\n",
        "# Relationship extraction"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}