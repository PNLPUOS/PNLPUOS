{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import gensim\n",
    "from nearpy import Engine\n",
    "from nearpy.hashes import RandomBinaryProjections\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLobal variables.\n",
    "wordlist_en = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "N_TOPICS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definitions.\n",
    "class Cluster:\n",
    "    def __init__(self, c_cl=None, me_cl=None, i_cl=None, l_cl=None):\n",
    "        self.c_cl = c_cl\n",
    "        self.me_cl = me_cl\n",
    "        self.l_cl =  l_cl\n",
    "        self.i_cl = i_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "df = pd.read_csv(\"../../data/pnlp_data_en.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize comments into sentences.\n",
    "corpus = ''\n",
    "for line in df['Comments']:\n",
    "    corpus += line.lower() + ' '\n",
    "\n",
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "trainer.train(corpus)\n",
    " \n",
    "tokenizer = PunktSentenceTokenizer(trainer.get_params())\n",
    "\n",
    "comments_tokenized = []\n",
    "for comment in df['Comments']:\n",
    "    for sentence in tokenizer.tokenize(comment):\n",
    "        comments_tokenized.append(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec news model.\n",
    "vector_path = 'GoogleNewsVectors300.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(vector_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length dataset: 24197\n",
      "Example comment: we do what our customers need, we communicate aperiodically.\n"
     ]
    }
   ],
   "source": [
    "# Clean comments for any unwanted elements. Consider adjusting based on clustering goals.\n",
    "comments_cleaned = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordlist_en = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "for i in range(len(comments_tokenized)):\n",
    "    tokens = nltk.tokenize.word_tokenize(comments_tokenized[i])\n",
    "    tokens_filtered = [w for w in tokens if w in wordlist_en and not w in stop_words]\n",
    "    if len(tokens_filtered) > 1:\n",
    "        comments_cleaned.append(comments_tokenized[i].replace('xxxx', '').replace('*', '')) \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# Inspect the dataset.\n",
    "print(\"Length dataset: {}\".format(len(comments_cleaned)))\n",
    "print(\"Example comment: {}\".format(comments_cleaned[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a new data structure to keep things cleaner.\n",
    "comments = comments_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean embeddings for each comment.\n",
    "mean_embeddings = []\n",
    "for i in range(len(comments)):\n",
    "    tokens = nltk.tokenize.word_tokenize(comments[i])\n",
    "    tokens_filtered = [w for w in tokens if not w in stop_words]\n",
    "    \n",
    "    embeddings = []\n",
    "    for token in tokens_filtered:\n",
    "        try:\n",
    "            embeddings.append(model[token])\n",
    "        except KeyError as e:\n",
    "            # Ignore the word if it does not exist.\n",
    "            pass\n",
    "    \n",
    "    mean_embedding = np.array(embeddings).mean(axis=0)\n",
    "    mean_embeddings.append(mean_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a clustering algorithm on the data given the number of topics.\n",
    "n_clusters = N_TOPICS\n",
    "ward = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward').fit(mean_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the cluster data.\n",
    "cluster_labels = ward.labels_\n",
    "merged = []\n",
    "for i in range(len(comments)):\n",
    "    tpl = (comments[i], mean_embeddings[i], cluster_labels[i])\n",
    "    merged.append(tpl)\n",
    "    \n",
    "df_merged = pd.DataFrame(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the list of cluster data objects.\n",
    "clusters = []\n",
    "for i in range(n_clusters):\n",
    "    c = df_merged[0][df_merged[2] == i]\n",
    "    me = df_merged[1][df_merged[2] == i]    \n",
    "    cluster = Cluster(c_cl=c, me_cl=me, i_cl=i)\n",
    "    clusters.append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label clusters with frequency analysis of the comments.\n",
    "for i in range(len(clusters)):\n",
    "    nouns_in_segments = []\n",
    "    for line in clusters[i].c_cl:\n",
    "        nouns = set()\n",
    "        text = nltk.word_tokenize(line)\n",
    "        text_tagged = nltk.pos_tag(text)\n",
    "        for tpl in text_tagged:\n",
    "            if tpl[1] == 'NN' or tpl[1] == 'NNS':\n",
    "                nouns.add(tpl[0])\n",
    "\n",
    "        nouns_in_segments.append(nouns)\n",
    "\n",
    "    frequency_evaluation = []\n",
    "    for segment_x in nouns_in_segments:\n",
    "        for segment_y in nouns_in_segments:\n",
    "            intersection = segment_x.intersection(segment_y)\n",
    "            if len(intersection) > 0:\n",
    "                for item in list(intersection):\n",
    "                    frequency_evaluation.append(item)\n",
    "\n",
    "    counter = collections.Counter(frequency_evaluation)\n",
    "    most_common = counter.most_common(30)\n",
    "    most_frequent = []\n",
    "    for item in most_common:\n",
    "        tpl = (item[0], item[1] / len(frequency_evaluation), item[1], len(frequency_evaluation))\n",
    "        most_frequent.append(tpl)\n",
    "    \n",
    "    clusters[i].l_cl = most_frequent[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1:company\n",
      "Sample Comments: \n",
      "customs business development continues to grow and expand, through the use of our internal business network & the team of people which are in place at the moment\n",
      "to change the global forwarding business unit back to \"forwarding mode\" is very good.\n",
      "however it is important these roles are distributed to the correct people and not some management level where the customer relationship is not supported\n",
      "lots of big and positive changes taken place.\n",
      "working towards new application cw1 also implementing new changes in old and new applications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 2:company\n",
      "Sample Comments: \n",
      "i am happy to inform that  got monthly salary, uniform, air ticket and weekly fruit on time.\n",
      "(please refrain from using people’s names or language that m\n",
      "we need more rest most especially night shift at least deserves 2 days off.\n",
      "our value adds for larger bc, mnc and csi are really working well,\n",
      "our office as a whole works very well together.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 3:team\n",
      "Sample Comments: \n",
      "i think the team work hard, are committed to continuous improvement and doing a good job for our customers.\n",
      "i think the company vision and goals are well set up and are quite inspiring and it is off course a globally recognisable brand.\n",
      "we are currently sharing good team bonding.\n",
      "realistic targets set and focus on service excellence\n",
      "overall team is committed to customers and doing good work\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 4:work\n",
      "Sample Comments: \n",
      "working well is giving your best in all aspects.\n",
      "working well is all about doing your job/work right at the first time.\n",
      "i can say the mission are all getting done!\n",
      "this type of relationship goes beyond rate.\n",
      "regular customers that that ship with us are the only thing that goes well around here.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 5:communication\n",
      "Sample Comments: \n",
      "we do what our customers need, we communicate aperiodically.\n",
      "all the channels of communications are effectively used.\n",
      "communication is very good.\n",
      "really love to work on critical shipments with efficiency to deliver excellence to all the customer.this is possible by taking ownership of the shipment and team work.\n",
      "popper communication and time management\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 6:training\n",
      "Sample Comments: \n",
      "working well is doing a great job with efficiency, accuracy, timelibess and meeting the expectation of the customer\n",
      "training and proper endorsement of job description for the newly hired/promoted employees\n",
      "i believe that i have a lot to contribute to a team environment; i love to help resolve issues, provide solutions to our customers/ business partners.\n",
      "i would like more training when you gets a new position.\n",
      "sometimes you receive o or two day to lear all the operation, but if we give more training we can avoid mistakes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 7:teamwork\n",
      "Sample Comments: \n",
      "managers are approachable, understanding and motivating.\n",
      "this has translated to increase coordination and teamwork between sales, operations and management.\n",
      "communication, learning and development, teamwork\n",
      "there is a passion for improvement and accuracy.\n",
      "collaboration between different functions.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 8:salary\n",
      "Sample Comments: \n",
      "post cif our performance have increased to satisfy our customer more\n",
      "sales exchange tariff ( outstanding tool) easy , quick .\n",
      "i hope the rates are profitable\n",
      "night shift allowance, would be better if increased.\n",
      "good feedback on improving the bonus incentive scheme  2.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 9:employees\n",
      "Sample Comments: \n",
      "i like the idea of customer 'ownership' at desk level where the contact is daily and productive.\n",
      "for you to do this, you need to have the positive mindset and the willingness to do it.\n",
      "the focus back to customer service at the desk level.\n",
      "it is too early to tell but i believe that the new mgmt.\n",
      "dedication of all employees under trying times\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cluster 10:customer\n",
      "Sample Comments: \n",
      "overall working towards a customer centric environment is working well and more effective teamwork within the company\n",
      "customer centricity is a growing culture in the company creating a very positive customer experience\n",
      "•develop a comfortable rapport with clients and determine their preferences for products and services  •resolve customer complaints with patience and creativity.\n",
      "the customer is the center.\n",
      "we are usually seeking customer satisfaction, helping our custom on fixing problems what ever it is related to [company] or not.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review the comment clusters and proposed labels.\n",
    "for cluster in clusters:\n",
    "    print(\"Cluster \" + str(cluster.i_cl+1) + \":\" + str(cluster.l_cl))\n",
    "    print(\"Sample Comments: \\n\", end='')\n",
    "    for comment in [comment for comment in cluster.c_cl][0:5]:\n",
    "        print(comment)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare mean embeddings for visualization.\n",
    "filedata = 'mean_embeddings_full_clustered_03.tsv'\n",
    "filelabels = 'mean_embeddings_full_clustered_labels_03.tsv'\n",
    "with open(filedata, 'w', newline='', encoding='utf-8') as f1:\n",
    "    tsv_output1 = csv.writer(f1, delimiter='\\t')\n",
    "    with open(filelabels, 'a', newline='', encoding='utf-8') as f2:\n",
    "        tsv_output2 = csv.writer(f2, delimiter='\\t')\n",
    "        tsv_output2.writerow(['comment', 'label'])\n",
    "        for cluster in clusters:\n",
    "            for i in range(len(cluster.c_cl)):\n",
    "                comment = [comment for comment in cluster.c_cl][i]\n",
    "                label = cluster.l_cl\n",
    "                metadata = [comment, label]\n",
    "                me_values = [me for me in cluster.me_cl][i]\n",
    "                \n",
    "                tsv_output1.writerow(me_values)\n",
    "                tsv_output2.writerow(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the mean embeddings via TensorFlow Projector.\n",
    "\n",
    "# https://projector.tensorflow.org/\n",
    "# Load both the embeddings and labels .tsv files.\n",
    "# Use UMAP visualization.\n",
    "# Color by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write 'comments_cleaned' to a file so i don't have to wait so long.\n",
    "# TODO: Make a new, clean notebook and push all the new stuff to git.\n",
    "# TODO: Make a new Word2Vec model with more dimensions and run it overnight.\n",
    "# https://wikipedia2vec.github.io/wikipedia2vec/pretrained/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
